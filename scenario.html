<!DOCTYPE html>
<html>
<head>
  <title>Scenario: Rare AI Policy Violations</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>

<h1>Scenario Analysis</h1>
<h2>Rare AI Policy Violations at Global Scale</h2>

<h3>Assumptions</h3>
<ul>
  <li>Daily prompts: 500,000,000</li>
  <li>Violation rate: 1 per 1,000,000 prompts</li>
  <li>Violations per day: ~500</li>
  <li>Assumptions are conservative and adjustable</li>
</ul>

<h3>Amplification Dynamics</h3>
<p>
Each violation represents a potential public artifact.
Screenshots, resharing, and reinterpretation rapidly
outpace internal detection and response.
</p>

<ul>
  <li>Average secondary exposure per incident: 1,000 users</li>
  <li>Estimated daily exposure: ~500,000 users</li>
  <li>Public narrative formation begins within hours</li>
</ul>

<h3>Escalation Timeline</h3>
<ul>
  <li><strong>T+0h:</strong> Isolated violations occur quietly</li>
  <li><strong>T+6h:</strong> Screenshots circulate out of context</li>
  <li><strong>T+24h:</strong> Narrative solidifies externally</li>
  <li><strong>T+72h:</strong> Regulatory and partner attention begins</li>
</ul>

<h3>Observed Gap</h3>
<p>
Internal mitigation timelines routinely exceed public tolerance.
The mismatch is structural, not procedural.
</p>

<h3>Takeaway</h3>
<p>
The risk is not the error rate.
The risk is the amplification math.
</p>

</body>
</html>
